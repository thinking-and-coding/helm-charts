# DocETL Configuration Reference

This document provides a comprehensive reference for all configuration parameters available in the DocETL Helm chart.

## Key Configuration Parameters

| Parameter | Description | Default |
|-----------|-------------|---------|
| `image.repository` | Docker image repository | `docetl` |
| `image.tag` | Docker image tag | `latest` |
| `image.pullPolicy` | Image pull policy | `IfNotPresent` |
| `backend.replicaCount` | Number of backend replicas | `1` |
| `backend.resources.limits.cpu` | Backend CPU limit | `2000m` |
| `backend.resources.limits.memory` | Backend memory limit | `4Gi` |
| `frontend.replicaCount` | Number of frontend replicas | `1` |
| `frontend.resources.limits.cpu` | Frontend CPU limit | `1000m` |
| `frontend.resources.limits.memory` | Frontend memory limit | `2Gi` |
| `backend.openaiApiKey` | OpenAI API Key | `your_api_key_here` |
| `ingress.enabled` | Enable Ingress | `true` |
| `ingress.className` | Ingress class name | `nginx` |
| `ingress.hosts[0].host` | Hostname for Ingress | `docetl.example.com` |
| `ingress.tls.enabled` | Enable TLS | `false` |
| `persistence.enabled` | Enable persistent storage | `true` |
| `persistence.size` | Size of PVC | `10Gi` |
| `persistence.storageClassName` | StorageClass name | `""` (default) |
| `persistence.accessMode` | PVC access mode | `ReadWriteOnce` |

## Image Configuration

```yaml
image:
  repository: docetl           # Docker image repository
  tag: latest                  # Image tag
  pullPolicy: IfNotPresent     # Pull policy: Always, IfNotPresent, Never
  pullSecrets: []              # Image pull secrets for private registries
```

**Important**: The `repository` field must be updated to your full registry path (e.g., `ghcr.io/your-org/docetl` or `your-registry.com/docetl`).

## Backend Configuration

```yaml
backend:
  replicaCount: 1              # Number of backend pods

  # OpenAI API Key (REQUIRED)
  openaiApiKey: "your_api_key_here"

  service:
    type: ClusterIP            # Service type: ClusterIP, NodePort, LoadBalancer
    port: 8000                 # Service port

  resources:
    requests:
      cpu: 500m                # CPU request
      memory: 1Gi              # Memory request
    limits:
      cpu: 2000m               # CPU limit
      memory: 4Gi              # Memory limit

  # Backend environment variables (see Environment Variables section)
  env:
    BACKEND_HOST: "0.0.0.0"
    BACKEND_PORT: "8000"
    BACKEND_RELOAD: "False"
    # ... more variables
```

## Frontend Configuration

```yaml
frontend:
  replicaCount: 1              # Number of frontend pods

  service:
    type: ClusterIP            # Service type
    port: 3000                 # Service port

  resources:
    requests:
      cpu: 250m                # CPU request
      memory: 512Mi            # Memory request
    limits:
      cpu: 1000m               # CPU limit
      memory: 2Gi              # Memory limit

  # Frontend environment variables (see Environment Variables section)
  env:
    FRONTEND_HOST: "0.0.0.0"
    FRONTEND_PORT: "3000"
    # ... more variables
```

## Environment Variables

### Backend Environment Variables

Configured in `values.yaml` under `backend.env`:

| Variable | Description | Default | Required |
|----------|-------------|---------|----------|
| `BACKEND_HOST` | Backend host address | `0.0.0.0` | Yes |
| `BACKEND_PORT` | Backend port | `8000` | Yes |
| `BACKEND_RELOAD` | Enable auto-reload (development) | `False` | No |
| `BACKEND_ALLOW_ORIGINS` | CORS allowed origins (auto-configured) | Frontend service URL | Yes |
| `TEXT_FILE_ENCODINGS` | Supported text file encodings | `utf-8,latin1,cp1252,iso-8859-1` | No |
| `DOCETL_HOME_DIR` | Data directory path | `/docetl-data` | Yes |
| `OPENAI_API_KEY` | OpenAI API key (from Secret) | - | Yes |

**Note**: Variables marked "auto-configured" are dynamically generated by the Helm chart using Kubernetes service DNS names.

### Frontend Environment Variables

Configured in `values.yaml` under `frontend.env`:

| Variable | Description | Default | Required |
|----------|-------------|---------|----------|
| `FRONTEND_HOST` | Frontend host address | `0.0.0.0` | Yes |
| `FRONTEND_PORT` | Frontend port | `3000` | Yes |
| `NEXT_PUBLIC_BACKEND_HOST` | Backend service DNS (auto-configured) | Backend service name | Yes |
| `NEXT_PUBLIC_BACKEND_PORT` | Backend service port (auto-configured) | `8000` | Yes |
| `NEXT_PUBLIC_HOSTED_DOCWRANGLER` | Hosted mode flag | `false` | No |

## Persistence Configuration

```yaml
persistence:
  enabled: true                # Enable persistent storage
  size: 10Gi                   # Size of PersistentVolumeClaim
  storageClassName: ""         # StorageClass name (empty = cluster default)
  accessMode: ReadWriteOnce    # Access mode: ReadWriteOnce, ReadWriteMany
  existingClaim: ""            # Use existing PVC instead of creating new
```

### Access Modes

- **ReadWriteOnce (RWO)**: Single node can mount for read/write (default)
- **ReadWriteMany (RWX)**: Multiple nodes can mount for read/write (requires compatible storage)

### Storage Classes

- Empty string `""`: Uses cluster default StorageClass
- Specific name: Uses named StorageClass (e.g., `"nfs-client"`, `"fast-ssd"`)
- Hyphen `"-"`: Disables dynamic provisioning (manual PV required)

### Multiple Backend Replicas

If you need multiple backend replicas for high availability:

1. Change `persistence.accessMode` to `ReadWriteMany`
2. Ensure your StorageClass supports ReadWriteMany (e.g., NFS, CephFS)
3. Update `backend.replicaCount` to desired number

Example:

```yaml
backend:
  replicaCount: 3

persistence:
  enabled: true
  size: 50Gi
  accessMode: ReadWriteMany
  storageClassName: "nfs-client"
```

## Ingress Configuration

```yaml
ingress:
  enabled: true                # Enable Ingress
  className: nginx             # Ingress class name

  annotations: {}              # Additional annotations
    # cert-manager.io/cluster-issuer: "letsencrypt-prod"
    # nginx.ingress.kubernetes.io/ssl-redirect: "true"

  hosts:
    - host: docetl.example.com
      paths:
        - path: /
          pathType: Prefix

  tls:
    enabled: false             # Enable TLS
    secretName: docetl-tls     # TLS secret name
```

### TLS Configuration

#### Option 1: Using cert-manager (Recommended)

```yaml
ingress:
  enabled: true
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
  tls:
    enabled: true
    secretName: docetl-tls
  hosts:
    - host: docetl.example.com
```

#### Option 2: Manual Certificate

```bash
# Create TLS secret
kubectl create secret tls docetl-tls \
  --cert=path/to/cert.crt \
  --key=path/to/cert.key \
  --namespace docetl
```

```yaml
ingress:
  enabled: true
  tls:
    enabled: true
    secretName: docetl-tls
```

## Service Account Configuration

```yaml
serviceAccount:
  create: true                 # Create ServiceAccount
  annotations: {}              # ServiceAccount annotations
  name: ""                     # ServiceAccount name (auto-generated if empty)
```

## Security Context

```yaml
podSecurityContext:
  fsGroup: 1000                # File system group

securityContext:
  runAsUser: 1000              # Run as user ID
  runAsNonRoot: true           # Enforce non-root
  capabilities:
    drop:
      - ALL                    # Drop all capabilities
```

## Node Selection

```yaml
nodeSelector: {}               # Node labels for pod assignment

tolerations: []                # Tolerations for node taints

affinity: {}                   # Affinity and anti-affinity rules
```

### Production Anti-Affinity Example

Spread backend pods across different nodes:

```yaml
backend:
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
                - key: app.kubernetes.io/component
                  operator: In
                  values:
                    - backend
            topologyKey: kubernetes.io/hostname
```

## Resource Requirements

### Minimum (Development)

```yaml
backend:
  resources:
    requests:
      cpu: 250m
      memory: 512Mi
    limits:
      cpu: 1000m
      memory: 2Gi

frontend:
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 1Gi
```

### Recommended (Production)

```yaml
backend:
  resources:
    requests:
      cpu: 500m
      memory: 1Gi
    limits:
      cpu: 2000m
      memory: 4Gi

frontend:
  resources:
    requests:
      cpu: 250m
      memory: 512Mi
    limits:
      cpu: 1000m
      memory: 2Gi
```

## Probes Configuration

### Liveness Probe

```yaml
backend:
  livenessProbe:
    enabled: true
    httpGet:
      path: /health
      port: 8000
    initialDelaySeconds: 30
    periodSeconds: 10
```

### Readiness Probe

```yaml
backend:
  readinessProbe:
    enabled: true
    httpGet:
      path: /health
      port: 8000
    initialDelaySeconds: 10
    periodSeconds: 5
```

## Example Configurations

See the `examples/` directory for complete configuration examples:

- **[values-basic.yaml](../examples/values-basic.yaml)**: Minimal setup for quick start
- **[values-dev.yaml](../examples/values-dev.yaml)**: Development environment
- **[values-prod.yaml](../examples/values-prod.yaml)**: Production-ready with HA, TLS, and security

## Configuration Validation

Validate your configuration before deploying:

```bash
# Template the chart with your values
helm template test ./charts/docetl -f my-values.yaml

# Dry-run installation
helm install test ./charts/docetl -f my-values.yaml --dry-run --debug

# Lint the configuration
helm lint ./charts/docetl -f my-values.yaml
```

## Next Steps

- Review [Security Best Practices](security.md) for production deployments
- Check [Installation Guide](installation.md) for deployment instructions
- See [Troubleshooting Guide](troubleshooting.md) for common issues
